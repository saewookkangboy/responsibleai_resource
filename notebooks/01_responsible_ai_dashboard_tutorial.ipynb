{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Responsible AI Dashboard Tutorial\n",
        "\n",
        "이 노트북은 Microsoft Responsible AI Toolbox 스타일의 종합적인 AI 모델 분석 방법을 소개합니다.\n",
        "\n",
        "## 학습 목표\n",
        "1. Responsible AI Dashboard를 사용한 모델 분석\n",
        "2. Error Analysis를 통한 오류 코호트 식별\n",
        "3. Counterfactual Analysis를 통한 개별 예측 설명\n",
        "4. Data Balance 분석을 통한 데이터 균형 평가\n",
        "5. Fairness Assessment를 통한 공정성 평가\n",
        "\n",
        "## 참고 자료\n",
        "- [Microsoft Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox)\n",
        "- [ResponsibleAI Dashboard](https://responsibleaitoolbox.ai/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 환경 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치 (필요시)\n",
        "# !pip install scikit-learn pandas numpy fairlearn shap\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '../responsible_ai_automation')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 경고 메시지 숨기기\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"환경 설정 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터 준비\n",
        "\n",
        "Adult Census Income 데이터셋을 사용하여 소득 예측 모델을 구축합니다.\n",
        "이 데이터셋은 공정성 분석에 자주 사용되는 벤치마크 데이터셋입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adult Census Income 데이터셋 생성 (시뮬레이션)\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "# 특성 생성\n",
        "data = {\n",
        "    'age': np.random.randint(18, 70, n_samples),\n",
        "    'education_years': np.random.randint(8, 20, n_samples),\n",
        "    'hours_per_week': np.random.randint(20, 60, n_samples),\n",
        "    'capital_gain': np.random.exponential(1000, n_samples).astype(int),\n",
        "    'capital_loss': np.random.exponential(100, n_samples).astype(int),\n",
        "    'gender': np.random.choice(['Male', 'Female'], n_samples, p=[0.6, 0.4]),\n",
        "    'race': np.random.choice(['White', 'Black', 'Asian', 'Other'], n_samples, p=[0.7, 0.15, 0.1, 0.05]),\n",
        "    'occupation': np.random.choice(['Tech', 'Sales', 'Service', 'Admin', 'Manual'], n_samples),\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 소득 레이블 생성 (일부 편향 포함)\n",
        "income_prob = (\n",
        "    0.3 + \n",
        "    0.02 * (df['education_years'] - 12) +\n",
        "    0.01 * (df['age'] - 30) / 10 +\n",
        "    0.001 * df['capital_gain'] / 1000 +\n",
        "    0.1 * (df['gender'] == 'Male').astype(int) +  # 의도적 편향\n",
        "    np.random.normal(0, 0.1, n_samples)\n",
        ")\n",
        "income_prob = np.clip(income_prob, 0.1, 0.9)\n",
        "df['income'] = (np.random.random(n_samples) < income_prob).astype(int)\n",
        "\n",
        "print(f\"데이터셋 크기: {len(df)}\")\n",
        "print(f\"\\n특성 목록: {list(df.columns)}\")\n",
        "print(f\"\\n레이블 분포:\\n{df['income'].value_counts()}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 모델 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 범주형 변수 인코딩\n",
        "categorical_features = ['gender', 'race', 'occupation']\n",
        "sensitive_features = ['gender', 'race']\n",
        "\n",
        "df_encoded = df.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    df_encoded[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = df_encoded.drop('income', axis=1)\n",
        "y = df_encoded['income'].values\n",
        "\n",
        "# 학습/테스트 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 기본 성능 확인\n",
        "train_acc = model.score(X_train, y_train)\n",
        "test_acc = model.score(X_test, y_test)\n",
        "\n",
        "print(f\"학습 정확도: {train_acc:.4f}\")\n",
        "print(f\"테스트 정확도: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Responsible AI Dashboard 생성\n",
        "\n",
        "Microsoft Responsible AI Toolbox 스타일의 종합 대시보드를 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.dashboard import ResponsibleAIDashboard, DashboardConfig\n",
        "\n",
        "# 대시보드 설정\n",
        "config = DashboardConfig(\n",
        "    title=\"소득 예측 모델 분석 대시보드\",\n",
        "    components=[\n",
        "        \"model_overview\",\n",
        "        \"error_analysis\",\n",
        "        \"fairness_assessment\",\n",
        "        \"data_explorer\",\n",
        "        \"counterfactual_analysis\",\n",
        "    ],\n",
        "    theme=\"light\",\n",
        "    locale=\"ko\",\n",
        ")\n",
        "\n",
        "# 대시보드 생성\n",
        "dashboard = ResponsibleAIDashboard(\n",
        "    model=model,\n",
        "    X_train=X_train,\n",
        "    y_train=y_train,\n",
        "    X_test=X_test,\n",
        "    y_test=y_test,\n",
        "    task_type=\"classification\",\n",
        "    sensitive_features=sensitive_features,\n",
        "    categorical_features=categorical_features,\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "print(\"Responsible AI Dashboard 생성 완료!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 모델 개요 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 개요 계산\n",
        "model_overview = dashboard.compute_model_overview()\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"모델 개요\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"태스크 유형: {model_overview['task_type']}\")\n",
        "print(f\"학습 샘플 수: {model_overview['train_samples']:,}\")\n",
        "print(f\"테스트 샘플 수: {model_overview['test_samples']:,}\")\n",
        "print(f\"특성 수: {model_overview['num_features']}\")\n",
        "print(f\"과적합 위험: {model_overview['overfitting_risk']}\")\n",
        "\n",
        "print(\"\\n테스트 성능 메트릭:\")\n",
        "for metric, value in model_overview['metrics'].items():\n",
        "    if metric != 'confusion_matrix':\n",
        "        print(f\"  - {metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Error Analysis (오류 분석)\n",
        "\n",
        "Microsoft Responsible AI Toolbox의 핵심 기능인 Error Analysis를 수행합니다.\n",
        "이를 통해 모델이 특히 성능이 낮은 데이터 코호트를 식별할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 오류 분석 수행\n",
        "error_analysis = dashboard.compute_error_analysis()\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Error Analysis 결과\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"전체 오류율: {error_analysis['overall_error_rate']:.2%}\")\n",
        "print(f\"총 샘플 수: {error_analysis['total_samples']:,}\")\n",
        "print(f\"총 오류 수: {error_analysis['total_errors']:,}\")\n",
        "\n",
        "print(\"\\n식별된 오류 코호트 (상위 5개):\")\n",
        "for i, cohort in enumerate(error_analysis['cohorts'][:5], 1):\n",
        "    print(f\"  {i}. {cohort['name']}\")\n",
        "    print(f\"     - 오류율: {cohort['error_rate']:.2%}\")\n",
        "    print(f\"     - 샘플 수: {cohort['size']:,}\")\n",
        "    print(f\"     - 커버리지: {cohort['coverage']:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Data Balance 분석\n",
        "\n",
        "데이터의 균형 상태를 분석하여 잠재적인 편향을 식별합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 균형 분석\n",
        "data_balance = dashboard.compute_data_balance()\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Data Balance 분석 결과\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 데이터셋 정보\n",
        "info = data_balance['dataset_info']\n",
        "print(f\"샘플 수: {info['num_samples']:,}\")\n",
        "print(f\"특성 수: {info['num_features']}\")\n",
        "\n",
        "# 레이블 균형\n",
        "if 'label_balance' in data_balance:\n",
        "    lb = data_balance['label_balance']\n",
        "    print(f\"\\n레이블 균형:\")\n",
        "    print(f\"  - 불균형 비율: {lb['imbalance_ratio']:.2f}:1\")\n",
        "    print(f\"  - 균형 상태: {'✓ 균형' if lb['is_balanced'] else '✗ 불균형'}\")\n",
        "\n",
        "# 민감한 속성 균형\n",
        "if 'sensitive_attribute_balance' in data_balance:\n",
        "    print(\"\\n민감한 속성별 균형:\")\n",
        "    for sb in data_balance['sensitive_attribute_balance']:\n",
        "        print(f\"\\n  {sb['attribute_name']}:\")\n",
        "        print(f\"    - Statistical Parity Difference: {sb['statistical_parity_difference']:.4f}\")\n",
        "        print(f\"    - Disparate Impact Ratio: {sb['disparate_impact_ratio']:.4f}\")\n",
        "        print(f\"    - 공정성: {'✓ 공정' if sb['is_fair'] else '✗ 불공정'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 종합 리포트 생성\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 종합 리포트 생성\n",
        "report = dashboard.generate_report()\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 요약\n",
        "\n",
        "이 튜토리얼에서 다룬 내용:\n",
        "\n",
        "1. **ResponsibleAIDashboard**: Microsoft RAI Toolbox 스타일의 통합 대시보드\n",
        "2. **Error Analysis**: 모델 오류 분석 및 문제가 되는 데이터 코호트 식별\n",
        "3. **Data Balance**: 데이터 균형 및 잠재적 편향 분석\n",
        "4. **Fairness Assessment**: 민감한 속성에 대한 공정성 평가\n",
        "\n",
        "### 참고 자료\n",
        "- [Microsoft Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox)\n",
        "- [ResponsibleAI Dashboard](https://responsibleaitoolbox.ai/)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
