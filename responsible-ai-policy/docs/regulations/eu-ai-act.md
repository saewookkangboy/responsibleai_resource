# EU AI Act (유럽연합 인공지능법)

## 개요

EU AI Act는 2024년에 승인된 유럽연합의 인공지능 규제 법안으로, AI 시스템의 위험 수준에 따라 차등 규제를 적용하는 세계 최초의 포괄적인 AI 규제 법안입니다.

## 법적 배경

### 제정 과정
- **2021년 4월**: 초안 발표
- **2024년 3월**: 유럽의회 승인
- **2024년 5월**: 이사회 최종 승인
- **2026년**: 전면 시행 예정

### 목적
- AI 시스템의 안전성과 신뢰성 확보
- 기본권 보호
- AI 혁신 촉진
- 단일 시장에서의 AI 활용 지원

## 위험 기반 분류

EU AI Act는 AI 시스템을 위험 수준에 따라 4가지로 분류합니다.

### 1. 금지된 AI 시스템 (Prohibited AI Systems)
완전히 금지되는 AI 시스템입니다.

**금지 사항:**
- 인간 행동 조작 (의식적 조작)
- 취약한 그룹 악용
- 사회 점수 시스템 (정부 운영)
- 원격 생체 인식 (실시간 공공 장소, 예외 있음)
- 감정 인식 (직장 및 교육, 예외 있음)

### 2. 고위험 AI 시스템 (High-Risk AI Systems)
엄격한 요구사항을 준수해야 하는 AI 시스템입니다.

**고위험 분야:**
- 생체 인식 시스템
- 중요 인프라 관리
- 교육 및 직업 훈련
- 고용, 근로자 관리
- 접근 가능한 공공 및 민간 서비스
- 법 집행
- 이민, 망명, 국경 통제
- 사법 행정 및 민주적 프로세스

**요구사항:**
- 위험 관리 시스템
- 데이터 거버넌스
- 기술 문서화
- 기록 보관
- 투명성 및 사용자 정보 제공
- 인간 감독
- 정확성, 견고성, 사이버 보안
- 적합성 평가
- 품질 관리 시스템
- 사후 모니터링

### 3. 제한적 위험 AI 시스템 (Limited-Risk AI Systems)
투명성 요구사항이 적용되는 AI 시스템입니다.

**요구사항:**
- 사용자에게 AI 사용 여부 명시
- 딥페이크 등 생성 AI 콘텐츠 표시

### 4. 최소 위험 AI 시스템 (Minimal-Risk AI Systems)
규제가 거의 없는 AI 시스템입니다.

**예시:**
- 스팸 필터
- 추천 시스템
- 게임 AI

## 핵심 요구사항

### 1. 위험 관리 시스템
- 지속적인 위험 평가
- 위험 완화 조치
- 위험 모니터링

### 2. 데이터 거버넌스
- 고품질 데이터 사용
- 편향 방지
- 데이터 보호

### 3. 기술 문서화
- 시스템 설계 문서
- 알고리즘 설명
- 테스트 결과

### 4. 기록 보관
- 시스템 사용 기록
- 의사결정 추적
- 감사 추적

### 5. 투명성
- 사용자에게 AI 사용 명시
- 의사결정 과정 설명
- 모델 정보 제공

### 6. 인간 감독
- 인간의 개입 가능성
- 인간의 의사결정 권한
- 자동화 제한

### 7. 정확성 및 견고성
- 높은 정확도 유지
- 다양한 조건에서 안정적 작동
- 오류 처리

### 8. 사이버 보안
- 보안 위협 방어
- 데이터 보호
- 시스템 무결성

## 적합성 평가

### 1. 자체 평가
- 개발자가 자체 평가 수행
- 기술 문서 작성
- 적합성 선언

### 2. 제3자 평가
- 고위험 시스템의 경우 제3자 평가 필요
- 인증 기관의 인증

### 3. 지속적 모니터링
- 시장 출시 후 모니터링
- 성능 추적
- 문제 발견 시 조치

## 제재 및 집행

### 1. 제재
- 최대 3,500만 유로 또는 전 세계 매출의 7% (더 큰 금액)
- 금지된 AI 사용 시 최대 3,500만 유로 또는 매출의 7%
- 기타 위반 시 최대 1,500만 유로 또는 매출의 3%

### 2. 집행 기관
- 각 회원국의 감독 기관
- 유럽 AI 사무소 (European AI Office)
- 유럽 AI 위원회 (European AI Board)

## 일반 목적 AI (GPAI) 규제

### 1. GPAI 정의
다양한 용도로 사용될 수 있는 범용 AI 모델입니다.

**예시:**
- 대형 언어 모델 (LLM)
- 생성형 AI 모델

### 2. 요구사항
- 기술 문서 제공
- 저작권 준수
- 투명성 보고서

### 3. 시스템적 위험 모델
매우 강력한 GPAI 모델은 추가 요구사항이 적용됩니다.

**기준:**
- 훈련에 사용된 연산량
- 모델 성능

**추가 요구사항:**
- 모델 평가
- 적대적 테스트
- 사이버 보안
- 인시던트 보고

## 서비스 개발에의 적용

### 1. 위험 평가
- AI 시스템의 위험 수준 평가
- 해당하는 규제 요구사항 확인
- 준수 계획 수립

### 2. 기술 문서화
- 시스템 설계 문서 작성
- 알고리즘 설명 문서
- 테스트 결과 기록

### 3. 적합성 평가
- 자체 평가 수행
- 필요 시 제3자 평가
- 적합성 선언

### 4. 지속적 모니터링
- 성능 모니터링
- 위험 추적
- 문제 발견 시 조치

### 5. 투명성 확보
- 사용자에게 AI 사용 명시
- 의사결정 과정 설명
- 모델 정보 제공

## 준수 체크리스트

### 고위험 AI 시스템
- [ ] 위험 관리 시스템 구축
- [ ] 데이터 거버넌스 정책 수립
- [ ] 기술 문서 작성
- [ ] 기록 보관 시스템 구축
- [ ] 투명성 요구사항 준수
- [ ] 인간 감독 메커니즘 구현
- [ ] 정확성 및 견고성 테스트
- [ ] 사이버 보안 조치
- [ ] 적합성 평가 수행
- [ ] 품질 관리 시스템 구축
- [ ] 사후 모니터링 시스템 구축

### 제한적 위험 AI 시스템
- [ ] 사용자에게 AI 사용 명시
- [ ] 생성 AI 콘텐츠 표시

### 일반 목적 AI
- [ ] 기술 문서 제공
- [ ] 저작권 준수
- [ ] 투명성 보고서 작성

## 참고 자료

- [EU AI Act 공식 문서](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)
- [유럽의회 AI Act 페이지](https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence)
- [EU AI Act 요약](https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence)

---

**중요**: EU AI Act는 2026년 전면 시행 예정이며, 세부 규정이 계속 업데이트될 수 있습니다. 최신 정보를 확인하시기 바랍니다.

