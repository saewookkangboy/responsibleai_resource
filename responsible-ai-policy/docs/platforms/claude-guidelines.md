# Claude AI Guidelines (Anthropic)

## 개요

Anthropic의 Claude AI는 안전하고 유용한 AI 시스템을 구축하기 위한 가이드라인을 제공합니다.

## 핵심 원칙

### 1. 유용성 (Helpfulness)
- 사용자의 의도를 정확히 이해
- 정확하고 관련성 있는 정보 제공
- 맥락에 맞는 응답 생성

### 2. 무해성 (Harmlessness)
- 유해한 콘텐츠 생성 방지
- 위험한 조언 제공 금지
- 편향된 정보 전달 방지

### 3. 정직성 (Honesty)
- 확실하지 않은 정보는 명시
- 추측과 사실 구분
- 정보 출처 제공 (가능한 경우)

## 보안 및 안전 정책

### 1. 콘텐츠 정책

#### 1.1 금지된 콘텐츠
- 불법 활동 조장
- 폭력 및 위험 행위
- 자해 및 자살 관련
- 성인 콘텐츠 (교육 목적 제외)
- 혐오 발언 및 차별

#### 1.2 제한된 콘텐츠
- 의료 조언 (전문가 검토 필수)
- 법률 조언 (변호사 상담 권장)
- 금융 조언 (투자 조언 면책)

### 2. 프라이버시 보호

#### 2.1 데이터 처리
- 대화 내용 암호화
- 데이터 최소화 원칙
- 사용자 동의 기반 처리

#### 2.2 데이터 보관
- 최소한의 보관 기간
- 자동 삭제 옵션
- 사용자 데이터 삭제 권리

#### 2.3 제3자 공유
- 명시적 동의 없이 공유 금지
- 법적 요구사항 시에만 공유
- 익명화된 데이터만 사용

### 3. 편향 방지

#### 3.1 공정성
- 다양한 관점 고려
- 성별, 인종, 종교 등 편향 방지
- 포용적 언어 사용

#### 3.2 투명성
- 편향 가능성 명시
- 모델의 한계 설명
- 개선 노력 공개

## Constitutional AI 원칙

Claude는 Constitutional AI 접근 방식을 사용하여 다음과 같은 원칙을 따릅니다:

### 1. 인간 존중
- 인간의 존엄성 존중
- 인권 보호
- 다양성 인정

### 2. 사회적 책임
- 사회적 이익 우선
- 환경 보호
- 지속 가능성

### 3. 투명성
- 의사결정 과정 공개
- 한계 명시
- 개선 노력 공유

## 서비스 개발에의 적용

### 웹 서비스
- 사용자 입력 검증
- 응답 필터링 시스템
- 프라이버시 설정 옵션
- 편향 모니터링

### 모바일 앱
- 로컬 데이터 암호화
- 최소 권한 원칙
- 사용자 제어 옵션
- 오프라인 처리 지원

### API 서비스
- 요청 검증
- 응답 필터링
- 사용량 제한
- 감사 로그

## 모범 사례

### 1. 프롬프트 엔지니어링
- 명확한 지시사항 제공
- 맥락 정보 포함
- 예상 응답 형식 지정

### 2. 안전성 검증
- 입력 검증
- 출력 필터링
- 유해 콘텐츠 감지

### 3. 사용자 경험
- 명확한 안내
- 오류 처리
- 피드백 수집

## 참고 자료

- [Anthropic AI Safety](https://www.anthropic.com/safety)
- [Claude Documentation](https://docs.anthropic.com/)
- [Constitutional AI](https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback)

