"""
ë¹ ë¥¸ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ - ìµœì†Œ ì„¤ì •ìœ¼ë¡œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from main import ResponsibleAIAutomationSystem


def quick_start():
    """ë¹ ë¥¸ ì‹œì‘ ì˜ˆì œ"""
    print("=" * 60)
    print("Responsible AI Automation ë¹ ë¥¸ ì‹œì‘")
    print("=" * 60)
    
    # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ìµœì†Œ ì„¤ì •)
    print("\n[1ë‹¨ê³„] ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
    config_path = Path(__file__).parent / "config.yaml"
    
    if not config_path.exists():
        print("âš  ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        create_default_config(config_path)
    
    system = ResponsibleAIAutomationSystem(str(config_path))
    print("âœ“ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # 2. ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    print("\n[2ë‹¨ê³„] ìƒ˜í”Œ ë°ì´í„° ìƒì„±...")
    X, y = make_classification(
        n_samples=1000,
        n_features=10,
        n_informative=5,
        n_redundant=2,
        n_classes=2,
        random_state=42
    )
    
    sensitive_features = pd.DataFrame({
        "gender": np.random.choice(["M", "F"], 1000),
        "race": np.random.choice(["A", "B", "C"], 1000),
    })
    
    X_train, X_test, y_train, y_test, sensitive_train, sensitive_test = train_test_split(
        X, y, sensitive_features, test_size=0.2, random_state=42
    )
    print(f"âœ“ ë°ì´í„° ìƒì„± ì™„ë£Œ (í›ˆë ¨: {len(X_train)}, í…ŒìŠ¤íŠ¸: {len(X_test)})")
    
    # 3. ëª¨ë¸ í•™ìŠµ
    print("\n[3ë‹¨ê³„] ëª¨ë¸ í•™ìŠµ...")
    model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    print("âœ“ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    
    # 4. ëª¨ë¸ ì´ˆê¸°í™”
    print("\n[4ë‹¨ê³„] Responsible AI ì‹œìŠ¤í…œì— ëª¨ë¸ ë“±ë¡...")
    system.initialize_model(model, X_test, y_test, sensitive_test)
    print("âœ“ ëª¨ë¸ ë“±ë¡ ì™„ë£Œ")
    
    # 5. í‰ê°€ ìˆ˜í–‰
    print("\n[5ë‹¨ê³„] Responsible AI í‰ê°€ ìˆ˜í–‰...")
    y_pred = model.predict(X_test)
    metrics = system.evaluate(X_test, y_test, y_pred, sensitive_test)
    
    # 6. ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("í‰ê°€ ê²°ê³¼")
    print("=" * 60)
    
    overall_score = metrics.get("overall_responsible_ai_score", 0.0)
    is_responsible = metrics.get("is_responsible", False)
    
    print(f"\nğŸ“Š ì „ì²´ Responsible AI ì ìˆ˜: {overall_score:.3f}")
    print(f"âœ… Responsible AI ê¸°ì¤€ ì¶©ì¡±: {'ì˜ˆ' if is_responsible else 'ì•„ë‹ˆì˜¤'}")
    
    print("\nì¹´í…Œê³ ë¦¬ë³„ ì ìˆ˜:")
    categories = {
        "fairness": "ê³µì •ì„±",
        "transparency": "íˆ¬ëª…ì„±",
        "accountability": "ì±…ì„ì„±",
        "privacy": "í”„ë¼ì´ë²„ì‹œ",
        "robustness": "ê²¬ê³ ì„±"
    }
    
    for key, name in categories.items():
        if key in metrics:
            score_key = f"overall_{key}_score"
            score = metrics[key].get(score_key, 0.0)
            print(f"  - {name}: {score:.3f}")
    
    print("\n" + "=" * 60)
    print("ë¹ ë¥¸ ì‹œì‘ ì™„ë£Œ! ğŸ‰")
    print("=" * 60)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("1. config.yaml íŒŒì¼ì„ ìˆ˜ì •í•˜ì—¬ ì„¤ì •ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ì„¸ìš”")
    print("2. ì‹¤ì œ ë°ì´í„°ë¡œ ëª¨ë¸ì„ í‰ê°€í•˜ì„¸ìš”")
    print("3. ì›¹ ëŒ€ì‹œë³´ë“œ ì‹¤í–‰: streamlit run src/monitoring/dashboard_web.py")
    print("4. API ì„œë²„ ì‹¤í–‰: python -m src.api.server")


def create_default_config(config_path: Path):
    """ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±"""
    default_config = """# Responsible AI Automation ê¸°ë³¸ ì„¤ì •

# í‰ê°€ ì„¤ì •
evaluation:
  fairness:
    metrics: ["demographic_parity", "equalized_odds"]
    threshold: 0.1
    sensitive_attributes: ["gender", "race"]
  
  transparency:
    metrics: ["explainability_score"]
    threshold: 0.7
  
  accountability:
    enabled: true
  
  privacy:
    metrics: ["data_anonymization", "access_control"]
    threshold: 0.8
  
  robustness:
    metrics: ["adversarial_robustness"]
    threshold: 0.75

# ê°•í™” í•™ìŠµ ì„¤ì • (ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´ ê°„ì†Œí™”)
reinforcement_learning:
  algorithm: "PPO"
  learning_rate: 3e-4
  batch_size: 64
  training_steps: 10000  # ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´ ê°ì†Œ

# ìë™ ì—…ë°ì´íŠ¸ ì„¤ì •
auto_update:
  enabled: false  # ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´ ë¹„í™œì„±í™”
  check_interval: 3600

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
monitoring:
  enabled: true
  dashboard_port: 8080
  log_level: "INFO"
  metrics_retention_days: 7  # ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´ ê°ì†Œ
  alert_channels:
    - "console"

# ëª¨ë¸ ì„¤ì •
model:
  save_path: "./models"
  checkpoint_frequency: 1000
  max_checkpoints: 5  # ë¹ ë¥¸ ì‹œì‘ì„ ìœ„í•´ ê°ì†Œ
"""
    
    config_path.parent.mkdir(parents=True, exist_ok=True)
    with open(config_path, "w", encoding="utf-8") as f:
        f.write(default_config)
    
    print(f"âœ“ ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")


if __name__ == "__main__":
    try:
        quick_start()
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        print("\në„ì›€ë§:")
        print("1. requirements.txtì˜ íŒ¨í‚¤ì§€ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        print("2. Python ë²„ì „ì´ 3.8 ì´ìƒì¸ì§€ í™•ì¸í•˜ì„¸ìš”")
        print("3. config.yaml íŒŒì¼ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”")

