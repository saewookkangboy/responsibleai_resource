# ì‚¬ìš© ì‚¬ë¡€ (Use Cases)

ì´ ë¬¸ì„œëŠ” Responsible AI Resourceë¥¼ ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì‹¤ì œ ì‚¬ë¡€ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“Š 1. ê¸ˆìœµ ì„œë¹„ìŠ¤

### ì‹œë‚˜ë¦¬ì˜¤
ì€í–‰ì—ì„œ ëŒ€ì¶œ ìŠ¹ì¸ ëª¨ë¸ì˜ ê³µì •ì„±ì„ í‰ê°€í•˜ê³  ê°œì„ í•©ë‹ˆë‹¤.

### êµ¬í˜„
```python
from main import ResponsibleAIAutomationSystem
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”
system = ResponsibleAIAutomationSystem("config.yaml")

# ëŒ€ì¶œ ë°ì´í„° ë¡œë“œ
loan_data = pd.read_csv("loan_data.csv")
X = loan_data.drop(["loan_approved"], axis=1)
y = loan_data["loan_approved"]
sensitive_features = loan_data[["gender", "race", "age"]]

# ëª¨ë¸ í•™ìŠµ
model = RandomForestClassifier(n_estimators=100)
model.fit(X, y)

# Responsible AI í‰ê°€
system.initialize_model(model, X.values, y.values, sensitive_features)
y_pred = model.predict(X.values)
metrics = system.evaluate(X.values, y.values, y_pred, sensitive_features)

# ê²°ê³¼ í™•ì¸
print(f"ê³µì •ì„± ì ìˆ˜: {metrics['fairness']['overall_fairness_score']:.3f}")
```

### ì£¼ìš” ê³ ë ¤ì‚¬í•­
- ë¯¼ê°í•œ ì†ì„±(ì„±ë³„, ì¸ì¢…, ë‚˜ì´)ë³„ ê³µì •ì„± í‰ê°€
- ê·œì œ ì¤€ìˆ˜ (EU AI Act, GDPR)
- íˆ¬ëª…ì„± ë° ì„¤ëª… ê°€ëŠ¥ì„±

---

## ğŸ¥ 2. í—¬ìŠ¤ì¼€ì–´

### ì‹œë‚˜ë¦¬ì˜¤
ì˜ë£Œ ì§„ë‹¨ ëª¨ë¸ì˜ í¸í–¥ì„±ì„ ê°ì§€í•˜ê³  í™˜ì í”„ë¼ì´ë²„ì‹œë¥¼ ë³´í˜¸í•©ë‹ˆë‹¤.

### êµ¬í˜„
```python
# ì˜ë£Œ ë°ì´í„° í‰ê°€
medical_data = pd.read_csv("medical_data.csv")
X = medical_data.drop(["diagnosis"], axis=1)
y = medical_data["diagnosis"]
sensitive_features = medical_data[["age", "gender", "socioeconomic_status"]]

# í”„ë¼ì´ë²„ì‹œ ê°•í™” ì„¤ì •
config = {
    "privacy": {
        "metrics": ["differential_privacy", "data_anonymization"],
        "threshold": 0.9,  # ë†’ì€ í”„ë¼ì´ë²„ì‹œ ìš”êµ¬ì‚¬í•­
    }
}

system = ResponsibleAIAutomationSystem("config.yaml")
# ... í‰ê°€ ìˆ˜í–‰
```

### ì£¼ìš” ê³ ë ¤ì‚¬í•­
- ë†’ì€ í”„ë¼ì´ë²„ì‹œ ìš”êµ¬ì‚¬í•­
- HIPAA ì¤€ìˆ˜
- í™˜ì ë°ì´í„° ë³´í˜¸

---

## ğŸ“ 3. êµìœ¡

### ì‹œë‚˜ë¦¬ì˜¤
ì…í•™ ì‹¬ì‚¬ ëª¨ë¸ì˜ ê³µì •ì„±ì„ í‰ê°€í•˜ê³  ê°œì„ í•©ë‹ˆë‹¤.

### êµ¬í˜„
```python
# ì…í•™ ë°ì´í„° í‰ê°€
admission_data = pd.read_csv("admission_data.csv")
X = admission_data.drop(["admitted"], axis=1)
y = admission_data["admitted"]
sensitive_features = admission_data[["gender", "ethnicity", "socioeconomic_background"]]

# ì‚¬íšŒì  ì˜í–¥ í‰ê°€ í¬í•¨
metrics = system.evaluate(
    X.values, y.values, y_pred, sensitive_features,
    include_social_impact=True
)
```

### ì£¼ìš” ê³ ë ¤ì‚¬í•­
- êµìœ¡ ê¸°íšŒì˜ ê³µì •ì„±
- ì‚¬íšŒì  ì˜í–¥ í‰ê°€
- íˆ¬ëª…ì„± ë° ì„¤ëª… ê°€ëŠ¥ì„±

---

## ğŸ’¼ 4. ì±„ìš©

### ì‹œë‚˜ë¦¬ì˜¤
ì±„ìš© ì§€ì›ì ì„ ë³„ ëª¨ë¸ì˜ í¸í–¥ì„±ì„ ê°ì§€í•˜ê³  ì™„í™”í•©ë‹ˆë‹¤.

### êµ¬í˜„
```python
# ì±„ìš© ë°ì´í„° í‰ê°€
hiring_data = pd.read_csv("hiring_data.csv")
X = hiring_data.drop(["hired"], axis=1)
y = hiring_data["hired"]
sensitive_features = hiring_data[["gender", "age", "ethnicity"]]

# ê³µì •ì„± ë©”íŠ¸ë¦­ ê°•í™”
config = {
    "fairness": {
        "metrics": [
            "demographic_parity",
            "equalized_odds",
            "equal_opportunity"
        ],
        "threshold": 0.05,  # ì—„ê²©í•œ ê³µì •ì„± ê¸°ì¤€
    }
}
```

### ì£¼ìš” ê³ ë ¤ì‚¬í•­
- ì°¨ë³„ ê¸ˆì§€ ë²•ë¥  ì¤€ìˆ˜
- ë‹¤ì–‘í•œ ë°°ê²½ì˜ ì§€ì›ì ê³µì •í•œ í‰ê°€
- ì„¤ëª… ê°€ëŠ¥í•œ ì˜ì‚¬ê²°ì •

---

## ğŸ¯ 5. ì¶”ì²œ ì‹œìŠ¤í…œ

### ì‹œë‚˜ë¦¬ì˜¤
ì½˜í…ì¸  ì¶”ì²œ ëª¨ë¸ì˜ ê³µì •ì„±ê³¼ íˆ¬ëª…ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤.

### êµ¬í˜„
```python
# ì¶”ì²œ ì‹œìŠ¤í…œ í‰ê°€
recommendation_data = pd.read_csv("recommendation_data.csv")
X = recommendation_data.drop(["clicked"], axis=1)
y = recommendation_data["clicked"]
sensitive_features = recommendation_data[["user_demographics"]]

# íˆ¬ëª…ì„± í‰ê°€ ê°•í™”
config = {
    "transparency": {
        "metrics": ["explainability_score", "feature_importance"],
        "threshold": 0.8,
    }
}
```

### ì£¼ìš” ê³ ë ¤ì‚¬í•­
- ì‚¬ìš©ì í”„ë¼ì´ë²„ì‹œ
- í•„í„° ë²„ë¸” ë°©ì§€
- ì¶”ì²œ ì´ìœ  ì„¤ëª… ê°€ëŠ¥ì„±

---

## ğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

### Adult ë°ì´í„°ì…‹

| ë©”íŠ¸ë¦­ | ê°’ |
|--------|-----|
| ê³µì •ì„± ì ìˆ˜ | 0.85 |
| íˆ¬ëª…ì„± ì ìˆ˜ | 0.78 |
| ì¢…í•© ì ìˆ˜ | 0.82 |

### COMPAS ë°ì´í„°ì…‹

| ë©”íŠ¸ë¦­ | ê°’ |
|--------|-----|
| ê³µì •ì„± ì ìˆ˜ | 0.88 |
| íˆ¬ëª…ì„± ì ìˆ˜ | 0.75 |
| ì¢…í•© ì ìˆ˜ | 0.81 |

---

## ğŸ”— ê´€ë ¨ ìë£Œ

- [íŠœí† ë¦¬ì–¼ 1: Responsible AI í‰ê°€ ì‹œì‘í•˜ê¸°](../responsible_ai_automation/docs/tutorial_01_evaluation.md)
- [í†µí•© ì‚¬ìš© ê°€ì´ë“œ](INTEGRATION_GUIDE.md)
- [API ë ˆí¼ëŸ°ìŠ¤](../responsible_ai_automation/docs/api_reference.md)

---

**Last Updated**: 2026-01-07

